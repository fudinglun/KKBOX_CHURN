{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import sparse\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('../1001_proj/train.csv/train.csv')\n",
    "test = pd.read_csv('../1001_proj/test.csv/test.csv')\n",
    "song = pd.read_csv('../1001_proj/songs.csv/songs.csv')\n",
    "members =  pd.read_csv('../1001_proj/members.csv/members.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = train.merge(song,on= 'song_id',how = 'left')\n",
    "test = test.merge(song,on = 'song_id',how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train, valid = train_test_split(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuf = train.groupby('msno')['target'].agg(['sum','count']) #Laplacian smoothing\n",
    "tuf = tuf.reset_index()\n",
    "tuf.columns.values[1:3] = ['user_sum','user_count']\n",
    "train = train.merge(tuf,on = 'msno',how = 'left')\n",
    "train['user_freq'] = (train.user_sum-train.target+1)/(train.user_count+1)\n",
    "train['user_count'] = train['user_count'] - 1\n",
    "train = train.drop('user_sum',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuf['user_freq'] = (tuf.user_sum+1)/(tuf.user_count+2)\n",
    "valid = valid.merge(tuf,on = 'msno',how = 'left')\n",
    "valid.loc[pd.isnull(valid.user_count),'user_count'] = 0\n",
    "valid.loc[pd.isnull(valid.user_freq),'user_freq'] = 0.5\n",
    "valid = valid.drop('user_sum',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tuf['user_freq'] = (tuf.user_sum+1)/(tuf.user_count+2)\n",
    "test = test.merge(tuf,on = 'msno',how = 'left')\n",
    "test.loc[pd.isnull(test.user_count),'user_count'] = 0\n",
    "test.loc[pd.isnull(test.user_freq),'user_freq'] = 0.5\n",
    "test = test.drop('user_sum',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tuf = train.groupby('song_id')['target'].agg(['sum','count']) #Laplacian smoothing\n",
    "tuf = tuf.reset_index()\n",
    "tuf.columns.values[1:3] = ['song_sum','song_count']\n",
    "train = train.merge(tuf,on = 'song_id',how = 'left')\n",
    "train['song_freq'] = (train.song_sum-train.target+1)/(train.song_count+1)\n",
    "train['song_count'] = train['song_count'] -1\n",
    "train = train.drop('song_sum',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tuf['song_freq'] = (tuf.song_sum+1)/(tuf.song_count+2)\n",
    "valid = valid.merge(tuf,on = 'song_id',how = 'left')\n",
    "valid.loc[pd.isnull(valid.song_count),'song_count'] = 0\n",
    "valid.loc[pd.isnull(valid.song_freq),'song_freq'] = 0.5\n",
    "valid = valid.drop('song_sum',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tuf['song_freq'] = (tuf.song_sum+1)/(tuf.song_count+2)\n",
    "test = test.merge(tuf,on = 'song_id',how = 'left')\n",
    "test.loc[pd.isnull(test.song_count),'song_count'] = 0\n",
    "test.loc[pd.isnull(test.song_freq),'song_freq'] = 0.5\n",
    "test = test.drop('song_sum',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split(x):\n",
    "    l = re.split(\"[+|&/]\",x)\n",
    "    l = [i.strip() for i in list(l)]\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train.artist_name = train.artist_name.fillna(\"no_rec\")\n",
    "valid.artist_name = valid.artist_name.fillna(\"no_rec\")\n",
    "test.artist_name = test.artist_name.fillna(\"no_rec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_art = set()\n",
    "for name in train.artist_name.unique():\n",
    "    train_art.add(name)\n",
    "    for sub in split(name):\n",
    "        train_art.add(sub.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "valid_art_diff = set()\n",
    "for name in valid.artist_name.unique():\n",
    "    indic = [sub.strip() in train_art for sub in split(name)]\n",
    "    if not any(indic):\n",
    "        valid_art_diff.add(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_art_diff = set()\n",
    "for name in test.artist_name.unique():\n",
    "    indic = [sub.strip() in train_art for sub in split(name)]\n",
    "    if not any(indic):\n",
    "        test_art_diff.add(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "valid_tt_csame = set()\n",
    "for name in valid.artist_name.unique():\n",
    "     if len(split(name)) > 1 and name in train_art:\n",
    "            valid_tt_csame.add(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tt_csame = set()\n",
    "for name in test.artist_name.unique():\n",
    "     if len(split(name)) > 1 and name in train_art:\n",
    "            tt_csame.add(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tt_single = set()\n",
    "for name in train.artist_name.unique():\n",
    "    if len(split(name)) == 1:\n",
    "        tt_single.add(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tt_cdump = set()\n",
    "for name in train.artist_name.unique():\n",
    "    if len(split(name)) > 1 and (not name in tt_csame or not name in valid_tt_csame):\n",
    "        tt_cdump.add(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "artdict = dict(zip(list(train_art),range(len(train_art))))\n",
    "userdict = dict(zip(train.msno.unique(),range(train.msno.nunique())))\n",
    "v = train.groupby(['msno','artist_name'])['target'].agg(['sum','count'])\n",
    "v = v.reset_index()\n",
    "v.columns.values[2:] = ['uasum','uacount']\n",
    "uamat = sparse.lil_matrix((len(userdict),2*len(artdict)))\n",
    "v['mind'] = v.msno.apply(lambda x: userdict[x])\n",
    "v['amind'] = v.artist_name.apply(lambda x: artdict[x])\n",
    "for i in v.index:\n",
    "    uamat[v.mind[i],2*v.amind[i]] = v.uasum[i]\n",
    "    uamat[v.mind[i],2*v.amind[i]+1] = v.uacount[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Dylan/anaconda/envs/3point6/lib/python3.6/site-packages/scipy/sparse/compressed.py:774: SparseEfficiencyWarning: Changing the sparsity structure of a csc_matrix is expensive. lil_matrix is more efficient.\n",
      "  SparseEfficiencyWarning)\n"
     ]
    }
   ],
   "source": [
    "disdict = {}\n",
    "for key, ind in artdict.items():\n",
    "    l = [artdict[sub] for sub in split(key) if not sub in tt_single]\n",
    "    if len(l) > 0:\n",
    "        disdict[key] = (l,ind)\n",
    "uamat = sparse.csc_matrix(uamat)\n",
    "for key, ind in disdict.items():\n",
    "    for sub in ind[0]:\n",
    "        uamat[:,2*sub] += uamat[:,2*ind[1]]\n",
    "        uamat[:,2*sub+1] += uamat[:,2*ind[1]+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "oart = train.groupby('artist_name')['target'].agg(['sum','count'])\n",
    "oart = oart.reset_index()\n",
    "oart.columns.values[1:3] = ['art_sum','art_count']\n",
    "train = train.merge(oart,on='artist_name',how = 'left')\n",
    "train['art_freq'] = (train.art_sum-train.target+1)/(train.art_count+1)\n",
    "traindump = train[train.artist_name.isin(list(tt_cdump))]\n",
    "train['is_art_dump'] = 0\n",
    "uasum = uamat.sum(axis = 0)\n",
    "for name,group in traindump.groupby(\"artist_name\"):\n",
    "    subind = np.array([artdict[sub.strip()] for sub in split(name)])\n",
    "    gasum = uasum[0,2*subind].sum()/len(subind)\n",
    "    gacount = uasum[0,2*subind+1].sum()/len(subind)\n",
    "    for ind in group.index:\n",
    "        train.set_value(ind,'art_sum',gasum)\n",
    "        train.set_value(ind,'art_count',gacount)\n",
    "        train.set_value(ind,'art_freq',gasum/gacount)\n",
    "        train.set_value(ind,'is_art_dump',1)\n",
    "train = train.drop('art_sum',1)\n",
    "train.art_count = train.art_count -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "oart['art_freq'] = oart.art_sum/oart.art_count\n",
    "valid = valid.merge(oart,on='artist_name',how = 'left')\n",
    "valid['is_art_dump'] = 0\n",
    "validnan = valid[pd.isnull(valid.art_sum)]\n",
    "for name, group in validnan.groupby(\"artist_name\"):\n",
    "    subind = np.array([artdict[sub.strip()] for sub in split(name) if sub.strip() in train_art])\n",
    "    if subind.size == 0:\n",
    "        for ind in group.index:\n",
    "            valid.set_value(ind,'art_count',0)\n",
    "            valid.set_value(ind,'art_freq',0.5)\n",
    "    else:\n",
    "        gasum = uasum[0,2*subind].sum()/len(subind)\n",
    "        gacount = uasum[0,2*subind+1].sum()/len(subind)\n",
    "        for ind in group.index:\n",
    "            valid.set_value(ind,'art_count',gacount)\n",
    "            valid.set_value(ind,'art_freq',gasum/gacount)\n",
    "            valid.set_value(ind,'is_art_dump',1)\n",
    "valid = valid.drop('art_sum',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = test.merge(oart,on='artist_name',how = 'left')\n",
    "test['is_art_dump'] = 0\n",
    "testnan = test[pd.isnull(test.art_sum)]\n",
    "for name, group in testnan.groupby(\"artist_name\"):\n",
    "    subind = np.array([artdict[sub.strip()] for sub in split(name) if sub.strip() in train_art])\n",
    "    if subind.size == 0:\n",
    "        for ind in group.index:\n",
    "            test.set_value(ind,'art_count',0)\n",
    "            test.set_value(ind,'art_freq',0.5)\n",
    "    else:\n",
    "        gasum = uasum[0,2*subind].sum()/len(subind)\n",
    "        gacount = uasum[0,2*subind+1].sum()/len(subind)\n",
    "        for ind in group.index:\n",
    "            test.set_value(ind,'art_count',gacount)\n",
    "            test.set_value(ind,'art_freq',gasum/gacount)\n",
    "            test.set_value(ind,'is_art_dump',1)\n",
    "test = test.drop('art_sum',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = train.merge(v,on = ['msno','artist_name'],how = 'left')\n",
    "train['uafreq'] = (train['uasum'] - train['target']+1)/(train['uacount']+1)\n",
    "train['uacount'] = train['uacount'] -1\n",
    "for name,group in train[train.artist_name.isin(list(tt_cdump))].groupby('artist_name'):\n",
    "    subcolin = np.array([artdict[sub.strip()] for sub in split(name)])\n",
    "    vsum = uamat[:,2*subcolin][group.mind,:].sum(axis =1)\n",
    "    vcount = uamat[:,2*subcolin+1][group.mind,:].sum(axis = 1)\n",
    "    gi = group.index ; gs = group.shape[0]\n",
    "    for i in range(gs):\n",
    "        train.set_value(gi[i],'uafreq',vsum[i]/vcount[i] if vcount[i] > 0 else 0.5)\n",
    "        train.set_value(gi[i],'uacount',vcount[i]/len(subcolin))\n",
    "train = train.drop(['mind','amind','uasum'],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Dylan/anaconda/envs/3point6/lib/python3.6/site-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "trainmsno = train.msno.unique()\n",
    "v['uafreq'] = v.uasum/v.uacount\n",
    "valid = valid.merge(v,on = ['msno','artist_name'],how = 'left')\n",
    "validnan = valid[pd.isnull(valid.uacount)]\n",
    "validnu = validnan[~validnan.msno.isin(trainmsno)]\n",
    "for name,group in validnu.groupby(['msno','artist_name']):\n",
    "    subcolin = np.array([artdict[sub.strip()] for sub in split(name[1]) if sub.strip() in train_art])\n",
    "    indic = len(subcolin) > 0 \n",
    "    overallfreq = uasum[0,2*subcolin].sum()/uasum[0,2*subcolin+1].sum() if indic else 0.5\n",
    "    for ind in group.index:\n",
    "        valid.set_value(ind,'uacount',0)\n",
    "        valid.set_value(ind,'uafreq',overallfreq)\n",
    "validrem = valid[pd.isnull(valid.uafreq)]\n",
    "validrem['mind']= validrem.msno.apply(lambda x: userdict[x])\n",
    "for name,group in validrem.groupby('artist_name'):\n",
    "    subcolin = np.array([artdict[sub.strip()] for sub in split(name) if sub.strip() in train_art])\n",
    "    if len(subcolin) > 0:\n",
    "        vsum = uamat[:,2*subcolin][group.mind,:].sum(axis = 1)\n",
    "        vcount = uamat[:,2*subcolin+1][group.mind,:].sum(axis =1)\n",
    "        gi = group.index\n",
    "        for i in range(group.shape[0]):\n",
    "            valid.set_value(gi[i],'uafreq',vsum[i]/vcount[i] if vcount[i] > 0 else 0.5)\n",
    "            valid.set_value(gi[i],'uacount',vcount[i]/len(subcolin))\n",
    "    else:\n",
    "        for ind in group.index:\n",
    "            valid.set_value(ind,'uacount',0)\n",
    "            valid.set_value(ind,'uafreq',group.user_freq[ind])\n",
    "valid = valid.drop(['mind','amind','uasum'],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Dylan/anaconda/envs/3point6/lib/python3.6/site-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "test = test.merge(v,on = ['msno','artist_name'],how = 'left')\n",
    "testnan = test[pd.isnull(test.uacount)]\n",
    "testnu = testnan[~testnan.msno.isin(trainmsno)]\n",
    "for name,group in testnu.groupby(['msno','artist_name']):\n",
    "    subcolin = np.array([artdict[sub.strip()] for sub in split(name[1]) if sub.strip() in train_art])\n",
    "    indic = len(subcolin) > 0 \n",
    "    overallfreq = uasum[0,2*subcolin].sum()/uasum[0,2*subcolin+1].sum() if indic else 0.5\n",
    "    for ind in group.index:\n",
    "        test.set_value(ind,'uacount',0)\n",
    "        test.set_value(ind,'uafreq',overallfreq)\n",
    "testrem = test[pd.isnull(test.uafreq)]\n",
    "testrem['mind']= testrem.msno.apply(lambda x: userdict[x])\n",
    "for name,group in testrem.groupby('artist_name'):\n",
    "    subcolin = np.array([artdict[sub.strip()] for sub in split(name) if sub.strip() in train_art])\n",
    "    if len(subcolin) > 0:\n",
    "        vsum = uamat[:,2*subcolin][group.mind,:].sum(axis = 1)\n",
    "        vcount = uamat[:,2*subcolin+1][group.mind,:].sum(axis =1)\n",
    "        gi = group.index\n",
    "        for i in range(group.shape[0]):\n",
    "            test.set_value(gi[i],'uafreq',vsum[i]/vcount[i] if vcount[i] > 0 else 0.5)\n",
    "            test.set_value(gi[i],'uacount',vcount[i]/len(subcolin))\n",
    "    else:\n",
    "        for ind in group.index:\n",
    "            test.set_value(ind,'uacount',0)\n",
    "            test.set_value(ind,'uafreq',group.user_freq[ind])\n",
    "test = test.drop(['mind','amind','uasum'],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.genre_ids = train.genre_ids.fillna('-1')\n",
    "test.genre_ids = test.genre_ids.fillna('-1')\n",
    "valid.genre_ids = valid.genre_ids.fillna('-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_genre = set()\n",
    "for genre in train.genre_ids:\n",
    "    train_genre.add(genre)\n",
    "    if not pd.isnull(genre) and \"|\" in genre:\n",
    "        for sub in genre.split(\"|\"):\n",
    "            train_genre.add(sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "valid_genre_diff = set()  #只有五个单个genre没有\n",
    "for name in valid.genre_ids.unique():\n",
    "    if not pd.isnull(name) and not \"|\" in name and not name in train_genre:\n",
    "        valid_genre_diff.add(name)\n",
    "    if not pd.isnull(name) and \"|\" in name:\n",
    "        indic = [x in train_genre for x in name.split(\"|\")]\n",
    "        if not any(indic):\n",
    "            valid_genre_diff.add(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_genre_diff = set()  #只有五个单个genre没有\n",
    "for name in test.genre_ids.unique():\n",
    "    if not pd.isnull(name) and not \"|\" in name and not name in train_genre:\n",
    "        test_genre_diff.add(name)\n",
    "    if not pd.isnull(name) and \"|\" in name:\n",
    "        indic = [x in train_genre for x in name.split(\"|\")]\n",
    "        if not any(indic):\n",
    "            test_genre_diff.add(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gsame = set()\n",
    "for genre in (list(test.genre_ids.unique()) + list(valid.genre_ids.unique())):\n",
    "    if not pd.isnull(genre) and \"|\" in genre and genre in train_genre:\n",
    "        train_gsame.add(genre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_gdump = set()\n",
    "for genre in train.genre_ids.unique():\n",
    "    if not pd.isnull(genre) and \"|\" in genre and not genre in train_gsame:\n",
    "        train_gdump.add(genre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_gsingle = [x for x in train.genre_ids.unique() if not pd.isnull(x) and not \"|\" in x]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "valid_newsingle = set()\n",
    "for x in valid.genre_ids.unique():\n",
    "    if not pd.isnull(x) and \"|\" in x:\n",
    "        indc = [sub for sub in x.split(\"|\") if sub in train_gsingle]\n",
    "        if len(indc) == 0:\n",
    "            valid_newsingle.add(sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_newsingle = set()\n",
    "for x in test.genre_ids.unique():\n",
    "    if not pd.isnull(x) and \"|\" in x:\n",
    "        indc = [sub for sub in x.split(\"|\") if sub in train_gsingle]\n",
    "        if len(indc) == 0:\n",
    "            test_newsingle.add(sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "valid_compnew = set()\n",
    "for genre in valid.genre_ids.unique():\n",
    "    if not pd.isnull(genre) and \"|\" in genre and not genre in train_genre:\n",
    "        for sub in genre.split(\"|\"):\n",
    "            if not sub in train_gsingle and sub in train_genre:\n",
    "                valid_compnew.add(genre) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_compnew = set()\n",
    "for genre in test.genre_ids.unique():\n",
    "    if not pd.isnull(genre) and \"|\" in genre and not genre in train_genre:\n",
    "        for sub in genre.split(\"|\"):\n",
    "            if not sub in train_gsingle and sub in train_genre:\n",
    "                test_compnew.add(genre) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Dylan/anaconda/envs/3point6/lib/python3.6/site-packages/scipy/sparse/compressed.py:774: SparseEfficiencyWarning: Changing the sparsity structure of a csc_matrix is expensive. lil_matrix is more efficient.\n",
      "  SparseEfficiencyWarning)\n"
     ]
    }
   ],
   "source": [
    "genredict = dict(zip(list(train_genre),range(len(train_genre))))\n",
    "ugmat = sparse.lil_matrix((len(userdict),2*len(genredict)))\n",
    "v = train.groupby(['msno','genre_ids'])['target'].agg(['sum','count'])\n",
    "v = v.reset_index()\n",
    "v.columns.values[2:] = ['ugsum','ugcount']\n",
    "v['mind'] = v.msno.apply(lambda x: userdict[x])\n",
    "v['gmind'] = v.genre_ids.apply(lambda x: genredict[x])\n",
    "for i in v.index:\n",
    "    ugmat[v.mind[i],2*v.gmind[i]] = v.ugsum[i]\n",
    "    ugmat[v.mind[i],2*v.gmind[i]+1] = v.ugcount[i]\n",
    "ugmat = sparse.csc_matrix(ugmat)\n",
    "for dump in train.genre_ids.unique():\n",
    "    subp = [dumpart for dumpart in dump.split(\"|\") if dumpart not in train_gsingle]\n",
    "    for sub in subp:\n",
    "        ugmat[:,2*genredict[sub]] += ugmat[:,2*genredict[dump]]\n",
    "        ugmat[:,2*genredict[sub]+1] += ugmat[:,2*genredict[dump]+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ogenre = train.groupby('genre_ids')['target'].agg(['sum','count'])\n",
    "ogenre = ogenre.reset_index()\n",
    "ogenre.columns.values[1:3] = ['genre_sum','genre_count']\n",
    "train.genre_ids = train.genre_ids.astype('str')\n",
    "ogenre.genre_ids = ogenre.genre_ids.astype('str')\n",
    "train = train.merge(ogenre,on='genre_ids',how = 'left')\n",
    "train['genre_freq'] = (train.genre_sum-train.target+1)/(train.genre_count+1)\n",
    "traindump = train[train.genre_ids.isin(list(train_gdump))]\n",
    "train['is_genre_dump'] = 0\n",
    "ugsum = ugmat.sum(axis = 0)\n",
    "for name,group in traindump.groupby(\"genre_ids\"):\n",
    "    subind = np.array([genredict[sub] for sub in name.split(\"|\")])\n",
    "    gasum = ugsum[0,2*subind].sum()/len(subind)\n",
    "    gacount = ugsum[0,2*subind+1].sum()/len(subind)\n",
    "    for ind in group.index:\n",
    "        train.set_value(ind,'genre_sum',gasum)\n",
    "        train.set_value(ind,'genre_count',gacount)\n",
    "        train.set_value(ind,'genre_freq',gasum/gacount)\n",
    "        train.set_value(ind,'is_genre_dump',1)\n",
    "train = train.drop('genre_sum',1)\n",
    "train.genre_count = train.genre_count -1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ogenre['genre_freq'] = ogenre.genre_sum/ogenre.genre_count\n",
    "valid = valid.merge(ogenre,on='genre_ids',how = 'left')\n",
    "valid['is_genre_dump'] = 0\n",
    "validnan = valid[pd.isnull(valid.genre_sum)]\n",
    "for name, group in validnan.groupby(\"genre_ids\"):\n",
    "    if not \"|\" in name:\n",
    "        for ind in group.index:\n",
    "            valid.set_value(ind,'genre_count',0)\n",
    "            valid.set_value(ind,'genre_freq',0.5)\n",
    "    else:\n",
    "        subind = np.array([genredict[sub] for sub in name.split(\"|\") if sub in train_genre])\n",
    "        gasum = ugsum[0,2*subind].sum()/len(subind)\n",
    "        gacount = ugsum[0,2*subind+1].sum()/len(subind)\n",
    "        for ind in group.index:\n",
    "            valid.set_value(ind,'genre_count',gacount)\n",
    "            valid.set_value(ind,'genre_freq',gasum/gacount)\n",
    "            valid.set_value(ind,'is_genre_dump',1)\n",
    "valid = valid.drop('genre_sum',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ogenre['genre_freq'] = ogenre.genre_sum/ogenre.genre_count\n",
    "test = test.merge(ogenre,on='genre_ids',how = 'left')\n",
    "test['is_genre_dump'] = 0\n",
    "testnan = test[pd.isnull(test.genre_sum)]\n",
    "for name, group in testnan.groupby(\"genre_ids\"):\n",
    "    if not \"|\" in name:\n",
    "        for ind in group.index:\n",
    "            test.set_value(ind,'genre_count',0)\n",
    "            test.set_value(ind,'genre_freq',0.5)\n",
    "    else:\n",
    "        subind = np.array([genredict[sub] for sub in name.split(\"|\") if sub in train_genre])\n",
    "        gasum = ugsum[0,2*subind].sum()/len(subind)\n",
    "        gacount = ugsum[0,2*subind+1].sum()/len(subind)\n",
    "        for ind in group.index:\n",
    "            test.set_value(ind,'genre_count',gacount)\n",
    "            test.set_value(ind,'genre_freq',gasum/gacount)\n",
    "            test.set_value(ind,'is_genre_dump',1)\n",
    "test = test.drop('genre_sum',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = train.merge(v,on = ['msno','genre_ids'],how = 'left')\n",
    "train['ugfreq'] = (train['ugsum'] - train['target']+1)/(train['ugcount']+1)\n",
    "train['ugcount'] = train['ugcount'] -1\n",
    "for name,group in train[train.genre_ids.isin(list(train_gdump))].groupby('genre_ids'):\n",
    "    subcolin = np.array([genredict[sub.strip()] for sub in name.split(\"|\")])\n",
    "    vsum = ugmat[:,2*subcolin][group.mind,:].sum(axis =1)\n",
    "    vcount = ugmat[:,2*subcolin+1][group.mind,:].sum(axis = 1)\n",
    "    gi = group.index ; gs = group.shape[0]\n",
    "    for i in range(gs):\n",
    "        train.set_value(gi[i],'ugfreq',vsum[i]/vcount[i] if vcount[i] > 0 else 0.5)\n",
    "        train.set_value(gi[i],'ugcount',vcount[i]/len(subcolin))\n",
    "train = train.drop(['mind','gmind','ugsum'],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Dylan/anaconda/envs/3point6/lib/python3.6/site-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "trainmsno = train.msno.unique()\n",
    "v['ugfreq'] = v.ugsum/v.ugcount\n",
    "valid = valid.merge(v,on = ['msno','genre_ids'],how = 'left')\n",
    "validnan = valid[pd.isnull(valid.ugcount)]\n",
    "validnu = validnan[~validnan.msno.isin(trainmsno)]\n",
    "for name,group in validnu.groupby(['msno','genre_ids']):\n",
    "    subcolin = np.array([genredict[sub.strip()] for sub in name[1].split(\"|\") if sub in train_genre])\n",
    "    overallfreq = ugsum[0,2*subcolin].sum()/ugsum[0,2*subcolin+1].sum()\n",
    "    indic = len(subcolin) > 0\n",
    "    for ind in group.index:\n",
    "        valid.set_value(ind,'ugcount',0)\n",
    "        valid.set_value(ind,'ugfreq',overallfreq if indic else 0.5)\n",
    "validrem = valid[pd.isnull(valid.ugfreq)]\n",
    "validrem['mind']= validrem.msno.apply(lambda x: userdict[x])\n",
    "for name,group in validrem.groupby('genre_ids'):\n",
    "    subcolin = np.array([genredict[sub.strip()] for sub in name.split(\"|\") if sub in train_genre])\n",
    "    if len(subcolin) > 0:\n",
    "        vsum = ugmat[:,2*subcolin][group.mind,:].sum(axis = 1)\n",
    "        vcount = ugmat[:,2*subcolin+1][group.mind,:].sum(axis =1)\n",
    "        gi = group.index\n",
    "        for i in range(group.shape[0]):\n",
    "            valid.set_value(gi[i],'ugfreq',vsum[i]/vcount[i] if vcount[i] > 0 else 0.5)\n",
    "            valid.set_value(gi[i],'ugcount',vcount[i]/len(subcolin))\n",
    "    else:\n",
    "        for ind in group.index:\n",
    "            valid.set_value(ind,'ugcount',0)\n",
    "            valid.set_value(ind,'ugfreq',group.user_freq[ind])\n",
    "valid = valid.drop(['mind','gmind','ugsum'],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Dylan/anaconda/envs/3point6/lib/python3.6/site-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "test = test.merge(v,on = ['msno','genre_ids'],how = 'left')\n",
    "testnan = test[pd.isnull(test.ugcount)]\n",
    "testnu = testnan[~testnan.msno.isin(trainmsno)]\n",
    "for name,group in testnu.groupby(['msno','genre_ids']):\n",
    "    subcolin = np.array([genredict[sub.strip()] for sub in name[1].split(\"|\") if sub in train_genre])\n",
    "    overallfreq = ugsum[0,2*subcolin].sum()/ugsum[0,2*subcolin+1].sum()\n",
    "    indic = len(subcolin) > 0\n",
    "    for ind in group.index:\n",
    "        test.set_value(ind,'ugcount',0)\n",
    "        test.set_value(ind,'ugfreq',overallfreq if indic else 0.5)\n",
    "testrem = test[pd.isnull(test.ugfreq)]\n",
    "testrem['mind']= testrem.msno.apply(lambda x: userdict[x])\n",
    "for name,group in testrem.groupby('genre_ids'):\n",
    "    subcolin = np.array([genredict[sub.strip()] for sub in name.split(\"|\") if sub in train_genre])\n",
    "    if len(subcolin) > 0:\n",
    "        vsum = ugmat[:,2*subcolin][group.mind,:].sum(axis = 1)\n",
    "        vcount = ugmat[:,2*subcolin+1][group.mind,:].sum(axis =1)\n",
    "        gi = group.index\n",
    "        for i in range(group.shape[0]):\n",
    "            test.set_value(gi[i],'ugfreq',vsum[i]/vcount[i] if vcount[i] > 0 else 0.5)\n",
    "            test.set_value(gi[i],'ugcount',vcount[i]/len(subcolin))\n",
    "    else:\n",
    "        for ind in group.index:\n",
    "            test.set_value(ind,'ugcount',0)\n",
    "            test.set_value(ind,'ugfreq',group.user_freq[ind])\n",
    "test = test.drop(['mind','gmind','ugsum'],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "rowin = train['msno'].unique()\n",
    "colin = train['song_id'].unique()\n",
    "spm = sparse.lil_matrix((len(rowin),len(colin)))\n",
    "dictuser = dict(zip(rowin,range(len(rowin))))\n",
    "dictsong = dict(zip(colin,range(len(colin))))\n",
    "for ind in train.index:\n",
    "    userp = dictuser[train.msno[ind]]\n",
    "    songp = dictsong[train.song_id[ind]]\n",
    "    spm[userp,songp] = (1 if train.target[ind] == 1 else -1)\n",
    "u_simi_song= cosine_similarity(spm)\n",
    "spm = sparse.csr_matrix(spm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop(['usbs', 'usbs_is_estimate', 'uind', 'rating'],1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "members['rtime'] = members['registration_init_time'].apply(\n",
    "    lambda x : pd.to_datetime(str(x), format='%Y%m%d'))\n",
    "members['etime'] = members['expiration_date'].apply(\n",
    "    lambda x : pd.to_datetime(str(x), format='%Y%m%d'))\n",
    "members['numactivedays'] = (members['etime'] - members['rtime']).dt.days\n",
    "min_day = members['rtime'].min()\n",
    "members['day_id_res'] = (members['rtime'] - min_day).dt.days+1\n",
    "members['day_id_exp'] = (members['etime'] - min_day).dt.days+1\n",
    "members['r_year'] = members['rtime'].dt.year\n",
    "members['r_month'] = members['rtime'].dt.month\n",
    "members['r_day'] = members['rtime'].dt.day\n",
    "members['e_year'] = members['etime'].dt.year\n",
    "members['e_month'] = members['etime'].dt.month\n",
    "members['e_day'] = members['etime'].dt.day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "members['is_male'] = members.gender == 'male'\n",
    "members['is_female'] = members.gender == 'female'\n",
    "members['age_mtrue'] = members.bd.apply(lambda x: 1 if x > 10 and x < 80 else 0)\n",
    "weighted_age = round(members.bd[members.age_mtrue == 1].mean())\n",
    "members['age_clean'] = members.bd.apply(lambda x: x if x >10 and x < 80 else weighted_age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = train.merge(members,on = 'msno', how = 'left')\n",
    "test = test.merge(members,on = 'msno', how = 'left')\n",
    "valid = valid.merge(members,on = 'msno', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def isrc_to_year(isrc):\n",
    "    if type(isrc) == str:\n",
    "        if int(isrc[5:7]) > 17:\n",
    "            return 1900 + int(isrc[5:7])\n",
    "        else:\n",
    "            return 2000 + int(isrc[5:7])\n",
    "    else:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs_extra = pd.read_csv('../1001_proj/song_extra_info.csv/song_extra_info.csv')\n",
    "songs_extra['song_year'] = songs_extra['isrc'].apply(isrc_to_year)\n",
    "songs_extra.drop(['isrc', 'name'], axis = 1, inplace = True)\n",
    "\n",
    "train = train.merge(songs_extra, on='song_id', how='left')\n",
    "test = test.merge(songs_extra, on='song_id', how='left')\n",
    "valid = valid.merge(songs_extra, on='song_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for col in train.columns:\n",
    "    if train[col].dtype == object:\n",
    "        train[col] = train[col].astype('category')\n",
    "        test[col] = test[col].astype('category')\n",
    "        valid[col] = valid[col].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import time\n",
    "train.rtime = train.rtime.apply(lambda x : time.mktime(x.timetuple()))\n",
    "train.etime = train.etime.apply(lambda x : time.mktime(x.timetuple()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "valid.rtime = valid.rtime.apply(lambda x : time.mktime(x.timetuple()))\n",
    "valid.etime = valid.etime.apply(lambda x : time.mktime(x.timetuple()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = train.drop(['target'], axis=1)\n",
    "y_train = train['target'].values\n",
    "\n",
    "X_valid = valid.drop(['target'], axis=1)\n",
    "y_valid = valid['target'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "lgb_train = lgb.Dataset(X_train, y_train)\n",
    "lgb_val = lgb.Dataset(X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Dylan/anaconda/envs/3point6/lib/python3.6/site-packages/lightgbm/engine.py:98: UserWarning: Found `num_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5]\tvalid_0's auc: 0.668207\n",
      "[10]\tvalid_0's auc: 0.672774\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "        'objective': 'binary',\n",
    "        'boosting': 'gbdt',\n",
    "        'learning_rate': 0.2 ,\n",
    "        'verbose': 0,\n",
    "        'num_leaves': 100,\n",
    "        'bagging_fraction': 0.95,\n",
    "        'bagging_freq': 1,\n",
    "        'bagging_seed': 1,\n",
    "        'feature_fraction': 0.9,\n",
    "        'feature_fraction_seed': 1,\n",
    "        'max_bin': 256,\n",
    "        'num_rounds': 10,\n",
    "        'metric' : 'auc'\n",
    "    }\n",
    "lgbm_model = lgb.train(params, train_set = lgb_train, valid_sets = lgb_val, verbose_eval=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.rtime = test.rtime.apply(lambda x : time.mktime(x.timetuple()))\n",
    "test.etime = test.etime.apply(lambda x : time.mktime(x.timetuple()))\n",
    "X_test = test.drop(['id'], axis=1)\n",
    "ids = test['id'].values\n",
    "predictions = lgbm_model.predict(X_test)\n",
    "\n",
    "# Writing output to file\n",
    "subm = pd.DataFrame()\n",
    "subm['id'] = ids\n",
    "subm['target'] = predictions\n",
    "subm.to_csv('lgbm_submission.csv.gz', compression = 'gzip', index=False, float_format = '%.5f')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (3.6)",
   "language": "python",
   "name": "3point6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
